{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2DwyRzNQSwBx"
   },
   "source": [
    "# Part 1 - Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BgS_ZteiSwBy"
   },
   "source": [
    "We will start with an Exploratory Data Analysis (EDA) of our SF housing dataset.  \n",
    "It is always best to start with an EDA before training a machine learning algorithm.  \n",
    "EDA gives us better insight to the data by using statistical and visualization techniques.  \n",
    "Most of these EDA techniques were adopted from various [Kaggle] kernels.  \n",
    "\n",
    "Upon completing this notebook, we should have:  \n",
    "* Familiarity with [Pandas] and [NumPy] for data management and analysis\n",
    "* Familiarity with [Matplotlib] and [seaborn] for visualization\n",
    "* A decent understanding of the characteristics of our dataset\n",
    "[Pandas]: https://pandas.pydata.org/\n",
    "[NumPy]: http://www.numpy.org/\n",
    "[Matplotlib]: https://matplotlib.org/\n",
    "[seaborn]: https://seaborn.pydata.org/\n",
    "[Kaggle]: https://www.kaggle.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2718,
     "status": "ok",
     "timestamp": 1525913486374,
     "user": {
      "displayName": "Kyle Hounslow",
      "photoUrl": "//lh5.googleusercontent.com/-EUCBmPgnjFM/AAAAAAAAAAI/AAAAAAAAAlg/Kla-xE5h8As/s50-c-k-no/photo.jpg",
      "userId": "116524524952241706076"
     },
     "user_tz": 420
    },
    "id": "rGLyu-oeh2DF",
    "outputId": "bcba7051-7d38-4ccc-d4e8-eb31120f6cc6"
   },
   "outputs": [],
   "source": [
    "# some python libs are missing if using Colab\n",
    "!pip install geopy geojson folium branca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "971I3-tMSwBz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from geopy import Nominatim\n",
    "import geojson\n",
    "import folium\n",
    "from branca.colormap import LinearColormap, StepColormap\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "arO9ObkhSwB1"
   },
   "source": [
    "## Let's start by loading the data and have a peek at the contents \n",
    "The data was scraped from [zillow.com](https://www.zillow.com/homes/for_sale/San-Francisco-CA/) and is dispersed between several csv files.  \n",
    "You can find the code used for scraping in [Github](https://github.com/kylehounslow/datasets/blob/master/mlbootcamp/scrape_zillow.ipynb) or [Open in Colab](https://colab.research.google.com/github/kylehounslow/datasets/blob/master/mlbootcamp/scrape_zillow.ipynb)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first download and extract the [dataset](https://github.com/kylehounslow/datasets/blob/master/mlbootcamp/sf_housing.zip), then use Pandas to load all csv files and concatenate them into a single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1102,
     "status": "ok",
     "timestamp": 1525911552312,
     "user": {
      "displayName": "Kyle Hounslow",
      "photoUrl": "//lh5.googleusercontent.com/-EUCBmPgnjFM/AAAAAAAAAAI/AAAAAAAAAlg/Kla-xE5h8As/s50-c-k-no/photo.jpg",
      "userId": "116524524952241706076"
     },
     "user_tz": 420
    },
    "id": "H7EI9lPCTCIc",
    "outputId": "d49a6d89-109d-4147-a8d0-b8b7420d35c5"
   },
   "outputs": [],
   "source": [
    "def download_extract_data(data_dir: str):\n",
    "    \"\"\"\n",
    "    Download zipfile and extract its contents to data_dir\n",
    "    Args:\n",
    "        data_dir: extract data here\n",
    "    \"\"\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    data_save_path = os.path.join(data_dir, 'data.zip')\n",
    "    data_download_url = 'https://github.com/kylehounslow/datasets/raw/master/mlbootcamp/sf_housing.zip'\n",
    "    print('downloading data...')\n",
    "    urllib.request.urlretrieve(data_download_url, data_save_path)\n",
    "    print('extracting data to {data_dir}...'.format(data_dir=data_dir))\n",
    "    data_zip = zipfile.ZipFile(data_save_path)\n",
    "    data_zip.extractall(data_dir)\n",
    "    data_zip.close()\n",
    "    print('Done.')\n",
    "\n",
    "def load_data_to_dataframe(data_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load all .csv files from data_dir and concatenate them into a single DataFrame.  \n",
    "    Args:\n",
    "        data_dir: path to data directory\n",
    "    Returns:\n",
    "        pd.DataFrame: all data from files in data_dir\n",
    "    Notes:\n",
    "        All duplicate rows will be discarded\n",
    "    \"\"\"\n",
    "    all_csvs = []\n",
    "    # load the csv files from all scraping runs\n",
    "    csv_filenames = os.path.join(data_dir, '**/*.csv')\n",
    "    print('loading data {csv_filenames}'.format(csv_filenames=csv_filenames))\n",
    "    for filename in glob.glob(csv_filenames):\n",
    "        all_csvs.append(pd.read_csv(filename))\n",
    "    # combine all dataframes together and drop any duplicate entries\n",
    "    df = pd.concat(all_csvs, ignore_index=True).drop_duplicates()\n",
    "    print(\"Found a total of {count} data points\".format(count=len(df)))\n",
    "    # save this combined dataframe as csv for safe keeping\n",
    "    df.to_csv(os.path.join(data_dir, 'all_data.csv'), index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and extract the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1128,
     "status": "ok",
     "timestamp": 1525911906949,
     "user": {
      "displayName": "Kyle Hounslow",
      "photoUrl": "//lh5.googleusercontent.com/-EUCBmPgnjFM/AAAAAAAAAAI/AAAAAAAAAlg/Kla-xE5h8As/s50-c-k-no/photo.jpg",
      "userId": "116524524952241706076"
     },
     "user_tz": 420
    },
    "id": "55ngYjzBYCVJ",
    "outputId": "d4837b32-8e90-4890-aff8-0a1f7e87bbca"
   },
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "download_extract_data(data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all data into DataFrame and preview the contents using `head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1128,
     "status": "ok",
     "timestamp": 1525911906949,
     "user": {
      "displayName": "Kyle Hounslow",
      "photoUrl": "//lh5.googleusercontent.com/-EUCBmPgnjFM/AAAAAAAAAAI/AAAAAAAAAlg/Kla-xE5h8As/s50-c-k-no/photo.jpg",
      "userId": "116524524952241706076"
     },
     "user_tz": 420
    },
    "id": "55ngYjzBYCVJ",
    "outputId": "d4837b32-8e90-4890-aff8-0a1f7e87bbca"
   },
   "outputs": [],
   "source": [
    "df_raw = load_data_to_dataframe(data_dir=data_dir)\n",
    "df_raw.head(5)  # display first 5 entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m0MW2-dcSwB6"
   },
   "source": [
    "### Our data is now contained in a variable named `df_raw` which is a pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6GL7MFrSwB7"
   },
   "source": [
    "## Display some quick stats about the DataFrame\n",
    "DataFrame has a few built in functions we can call to get a quick summary of the data:  \n",
    "* `info()` displays a count of all non-null objects and their datatypes  \n",
    "* `describe()` calculates basic statistics about all numerical values in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SEXrL436SwB8",
    "outputId": "7a741c6f-4def-420a-85a5-04d14c26414e"
   },
   "outputs": [],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SEXrL436SwB8",
    "outputId": "7a741c6f-4def-420a-85a5-04d14c26414e"
   },
   "outputs": [],
   "source": [
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mc3L-mgFSwB_"
   },
   "source": [
    "Many of the columns are not in a format ready for consumption. We still need to parse the data into numerical values.  \n",
    "For instance the `price` columns contain `$` and `,` characters and the `facts and features` column is a written sentence describing the number of beds, bath and square footage. \n",
    "  \n",
    "Let's parse and format these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OBV1CYm9SwCA"
   },
   "outputs": [],
   "source": [
    "# copy our original dataframe for safe keeping. We will manipulate `df` instead\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mkV-AzmRSwCC"
   },
   "source": [
    "## Reformat price column\n",
    "Time to use some convenient Pandas functions such as `.apply()` to apply a user defined formatting function to all values in a column.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WYJEmMRGSwCC"
   },
   "source": [
    "Remove `$` and `,` characters and format as `int`.  \n",
    "Also, some prices are represented as `$1K` and `$1M` so let's replace with `1000` and `1000000`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the price parsing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "oRzNTbcaSwCD"
   },
   "outputs": [],
   "source": [
    "def format_price(price):\n",
    "    \"\"\"Remove all non-numerical\"\"\"\n",
    "    price = str(price)\n",
    "    multiply_factor = 1\n",
    "    if 'M' in price:\n",
    "        multiply_factor = 1e6\n",
    "    elif 'K' in price:\n",
    "        multiply_factor = 1e3\n",
    "    non_decimal = re.compile(r'[^0-9\\.]')\n",
    "    price_num = None\n",
    "    try:\n",
    "        price_num = float(non_decimal.sub('', price))*multiply_factor\n",
    "    except Exception as e:\n",
    "#         print(f'error converting \\\"{price}\\\": {e}')\n",
    "        pass\n",
    "    finally:\n",
    "        return price_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply `format_price()` to all values in the `price` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df.price.apply(format_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8TegWFraSwCE"
   },
   "source": [
    "## Parse `facts and features` column into multiple columns \n",
    "An example entry in this column: `3 bds , 2 ba , 1,520 sqft`  \n",
    "Parse the text using comma followed by a space '`, `' as the delimiter so that we can still capture the comma in the square footage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parsing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8cTAyGafSwCF"
   },
   "outputs": [],
   "source": [
    "non_decimal = re.compile(r'[^\\d.]+') # regex for removing non-decimal characters from string\n",
    "def parse_beds(string):\n",
    "    strings = string.lower().split(', ')\n",
    "    num_beds = None\n",
    "    for s in strings:\n",
    "        if \"bd\" in s:\n",
    "            try:\n",
    "                num_beds = float(non_decimal.sub('', s))\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        # treat studio as 0 bedrooms\n",
    "        elif \"studio\" in s.lower():\n",
    "            num_beds = 0\n",
    "        return num_beds\n",
    "\n",
    "def parse_bath(string):\n",
    "    strings = string.lower().split(', ')\n",
    "    num_bath = None\n",
    "    for s in strings:\n",
    "        if \"ba\" in s:\n",
    "            try:\n",
    "                num_bath = float(non_decimal.sub('', s))\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            finally:\n",
    "                return num_bath\n",
    "def parse_sqft(string):\n",
    "    strings = string.lower().split(', ')\n",
    "    sqft = None\n",
    "    for s in strings:\n",
    "        if \"ft\" in s:\n",
    "            try:\n",
    "                sqft = float(non_decimal.sub('', s))\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            finally:\n",
    "                return sqft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply parsing functions to columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8cTAyGafSwCF"
   },
   "outputs": [],
   "source": [
    "df['bed'] = df['facts and features'].apply(parse_beds)\n",
    "df['bath'] = df['facts and features'].apply(parse_bath)\n",
    "df['sqft'] = df['facts and features'].apply(parse_sqft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4rxqD5TvSwCH"
   },
   "source": [
    "## Parse `title` column into `property_type`\n",
    "The title of the posting contains some information we can parse. For instance we can map `'Condo For Sale'` --> `condo`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g8xXnpDISwCI"
   },
   "source": [
    "First let's see if there is a pattern to the titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PKd_29kMSwCJ",
    "outputId": "4dcd01fa-2c70-42a7-a2bb-56ccc81063c3"
   },
   "outputs": [],
   "source": [
    "print(df.title.unique())\n",
    "print(df.title.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-GGWFXKdSwCL"
   },
   "source": [
    "Looks like there is a limited amount of unique values, which is good! We can design our parser to catch most cases.  \n",
    "We won't parse 'For Sale by Owner' since it is too vague"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parsing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0L_DSutwSwCL"
   },
   "outputs": [],
   "source": [
    "# property types mapping\n",
    "property_types = {'Condo For Sale': 'condo', \n",
    "                  'House For Sale': 'house', \n",
    "                  'Apartment For Sale': 'apartment', \n",
    "                  'New Construction': 'new',\n",
    "                  'Foreclosure': 'foreclosure', \n",
    "                   'Lot/Land For Sale': 'lot', \n",
    "                  'Coming Soon': 'coming', \n",
    "                  'Co-op For Sale': 'coop',\n",
    "                  'Auction': 'auction', \n",
    "                  'For Sale by Owner': None, \n",
    "                  'Townhouse For Sale': 'townhouse'}\n",
    "def parse_property_type(string):\n",
    "    try:\n",
    "        property_type = property_types[string]\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "        property_type = None\n",
    "    finally:\n",
    "        return property_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply parser to column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0L_DSutwSwCL"
   },
   "outputs": [],
   "source": [
    "df['property_type'] = df['title'].apply(parse_property_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lI1OnkmeSwCN",
    "outputId": "5f07d879-d29e-49d7-d4c5-6b138d4bb05d"
   },
   "outputs": [],
   "source": [
    "df.property_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ur6hKXf5SwCP"
   },
   "source": [
    "That's it for parsing!  \n",
    "Now if we check the `info()` of the dataframe, we should see some columns are now numerical (`float64`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5pIZu6CtSwCQ",
    "outputId": "da0b8b02-5b79-4270-b5eb-0283aaba770e"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qm-_6tPRSwCT"
   },
   "source": [
    "Now we can call `describe()` to get some stats about the numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EWEJzCrJSwCU",
    "outputId": "1a5d494b-76ec-48ad-dd56-549e9ca17347"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kNfd4huASwCW"
   },
   "source": [
    "### Very large maximum price...albeit not suprising. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YIBf5BM8SwCX",
    "outputId": "8c9f38b3-d109-44ca-ed6e-6199dd1fb412"
   },
   "outputs": [],
   "source": [
    "# describe only the 'price' column\n",
    "df['price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m2MjaHElSwCa"
   },
   "source": [
    "## We have the gist of the dataset size and its contents, it's time to go more in depth and Visualize the data.  \n",
    "We will use `Seaborn` to visualize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KK7Ej4RoSwCb"
   },
   "source": [
    "### Plot histogram of prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_1NXQG6RSwCb",
    "outputId": "1ce5d9c2-fbe0-4924-917a-66999b471645"
   },
   "outputs": [],
   "source": [
    "# globally set our seaborn plot size to 12 by 8 inches:\n",
    "sns.set(rc={'figure.figsize':(12, 8)})\n",
    "\n",
    "def plot_prices(df: pd.DataFrame, bins: list):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xticks(bins)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    return sns.distplot(df.price, bins=bins)\n",
    "\n",
    "bins = range(int(df.price.min()), int(df.price.max()), 500000)\n",
    "plot_prices(df.dropna(), bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgId10J6SwCd"
   },
   "source": [
    "### Definitely a skewed distribution, looks as if we have a few outliers at the higher range of the prices.  \n",
    "### We can quantify how \"non-normal\" our distribution is by calculating:  \n",
    "* `Skewness` - A measure of the symmetry (or lack thereof) of a distribution\n",
    "* `Kurtosis` - Whether distrubition is \"heavy-tailed\" or \"light-tailed\" or in other words: how \"sharp\" the peak is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "peMZDui8SwCe",
    "outputId": "3966700b-8795-43fd-9023-ceac7e903f06"
   },
   "outputs": [],
   "source": [
    "#skewness and kurtosis\n",
    "print(\"Skewness: %f\" % df['price'].skew())\n",
    "print(\"Kurtosis: %f\" % df['price'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HorYrnP8SwCf"
   },
   "source": [
    "## Plot with outliers removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UOf0CbM0SwCg",
    "outputId": "8eede0a9-80a2-4cbf-bbe0-ccccf4dbc35e"
   },
   "outputs": [],
   "source": [
    "df_no_outliers = df[df.price < 7e6]\n",
    "bins = range(int(df_no_outliers.price.min()),int(df_no_outliers.price.max()),500000)\n",
    "plot_prices(df_no_outliers, bins)\n",
    "print(\"Skewness (outliers removed): %f\" % df_no_outliers['price'].skew())\n",
    "print(\"Kurtosis (outliers removed): %f\" % df_no_outliers['price'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JQGdaacOSwCi"
   },
   "source": [
    "### Removing the outliers improved our skewness and kurtosis values.\n",
    "We will remember this when cleaning the data for our model. Machine learning models work best with normally distributed data. Outliers may affect model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S3VDRFf-SwCi"
   },
   "source": [
    "## Plot missing values.\n",
    "Recall that there were some columns which are incomplete. Plot a bar graph describing this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LkJGeLJvSwCj",
    "outputId": "ff509184-1991-4cc3-c0f7-5362d31db8e5"
   },
   "outputs": [],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "unVCdHgqSwCl"
   },
   "source": [
    "Variables that are missing values can either be removed from the dataset or have their missing values replaced (perhaps with 0 or the mean of the column). Remember this for data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B7LiWA1RSwCl"
   },
   "source": [
    "## Visualize the house prices w.r.t. location with a slippy map  \n",
    "We have some location information in the `address` column. We can use geocoding to convert the string address to Lat Long.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our geocoding function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3xwJBKMVSwCm"
   },
   "outputs": [],
   "source": [
    "NUM_RETRIES = 3 # number of retries for request\n",
    "def address_to_latlng(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch LatLng coords using Nominatim\n",
    "    \n",
    "    Args:\n",
    "        dataframe: pd.DataFrame containing `address` and `city` columns\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe with `latlng` column added\n",
    "        \n",
    "    \"\"\"\n",
    "    dataframe = dataframe.copy()\n",
    "    geocoder = Nominatim()\n",
    "    latlngs = []\n",
    "    print(\"fetching LatLng coords...\")\n",
    "    for address, city in zip(dataframe.address, dataframe.city):\n",
    "        time.sleep(int(random.randint(0,6)/3)) # try not to get your ip blacklisted by Nominatim\n",
    "        clear_output(wait=True)\n",
    "        location = None\n",
    "        for i in range(NUM_RETRIES):\n",
    "            try:\n",
    "                location = geocoder.geocode(f'{address} {city}')\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "        if location:\n",
    "            latlngs.append((location.latitude, location.longitude))\n",
    "        else:\n",
    "            latlngs.append(None)\n",
    "        print(f'{len(latlngs)+1}/{len(dataframe)} complete...')\n",
    "    dataframe['latlng'] = latlngs\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nql1mM6gSwCn"
   },
   "source": [
    "The above function `generate_latlng()` takes a while to run since we call a web service `Nominatim` to perform the address --> latlng lookup.  \n",
    "You can choose to load from a pre-processed csv file `data_w_latlng.csv` which is provided (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "umJqMeVxSwCo"
   },
   "outputs": [],
   "source": [
    "# uncomment below to fetch LatLng coords from Nominatim (takes a while ~30mins)\n",
    "################################################\n",
    "# df = address_to_latlng(df)\n",
    "# df.to_csv('data_w_latlng.csv', index=False)\n",
    "################################################\n",
    "# load pre-fetched latlng data\n",
    "df = pd.read_csv(os.path.join(data_dir, 'data_w_latlng.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe should now have a new `latlng` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hpvwwhtSSwCu",
    "outputId": "a5d7345d-f436-4471-bfaf-deeeba42eb57"
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WYWcve7bSwCw"
   },
   "source": [
    "We use [folium](https://github.com/python-visualization/folium) to render the slippy map in the notebook.  \n",
    "Note that there are hundreds of houses to be displayed and this requires a fair bit of RAM. If your browser crashes you can adjust the amount to be displayed by changing the variable `display_max`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define slippy map drawing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-V9SbI1ASwCy",
    "outputId": "deb64fe2-9785-4195-a175-b966ddb1404f"
   },
   "outputs": [],
   "source": [
    "def draw_houses_on_map(dataframe: pd.DataFrame):\n",
    "    dataframe = dataframe.copy()\n",
    "    # create a folium map object centered in SF\n",
    "    m = folium.Map(location=(37.7, -122.4))\n",
    "    # create a colormap of the prices (we limit prices between 5e5 and 10e6)\n",
    "    colors = ['gray', 'green','blue','red','orange', 'yellow']\n",
    "    min_price, max_price = 5e5, 6e6\n",
    "    colormap = StepColormap(colors=colors,vmin=min_price, vmax=max_price, caption='price')\n",
    "    m.add_child(colormap)\n",
    "    # amount of points to render on the map. WARNING: significant RAM required to plot all points and may crash your browser \n",
    "    display_max = len(dataframe) # plot all\n",
    "    # display_max = 100 # uncomment and adjust this number if needed\n",
    "    displayed = 0\n",
    "    for i, latlng in zip(dataframe.index, dataframe['latlng']):\n",
    "        price = dataframe.loc[i, 'price']\n",
    "        if latlng is not None:\n",
    "            if isinstance(latlng, str):\n",
    "                lat, lng = latlng.replace('(','').replace(')','').split(',')\n",
    "                latlng = (float(lat), float(lng))\n",
    "            if not isinstance(latlng, tuple):\n",
    "                continue\n",
    "            style = {'fillColor': colormap(price),\n",
    "                    'color' : colormap(price)}\n",
    "            p = geojson.Point(coordinates=(latlng[1], latlng[0]), style=style)\n",
    "            # build an HTML string to be displayed if we click a marker.\n",
    "            html_info = '<li>Price: ${}</li><li>Property Type: {}</li>'.format(dataframe.loc[i, 'price'], dataframe.loc[i, 'property_type'])\n",
    "            m.add_child(folium.Marker(location=latlng, icon=folium.Icon(color='black', icon_color=colormap(price)), popup=folium.Popup(html=html_info)))\n",
    "            displayed += 1\n",
    "            if displayed > display_max:\n",
    "                break\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw slippy map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-V9SbI1ASwCy",
    "outputId": "deb64fe2-9785-4195-a175-b966ddb1404f"
   },
   "outputs": [],
   "source": [
    "draw_houses_on_map(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "suop3niZSwC0"
   },
   "source": [
    "We can observe some patterns w.r.t. location.  \n",
    "The more expensive homes are Central and North and the \"lower\" (finger quotes) priced homes are South, West and East.\n",
    "\n",
    "## Next, let's see how some of the variables interact with the list price.  \n",
    "Since `price` is the dependent variable which we are trying to predict, it is important to visualize how it relates to the independent variables (`sqft`, `bed`, `bath`, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rW9VYuOuSwC1"
   },
   "source": [
    "### Plot `price` vs. `sqft`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SLEs_2HqSwC1",
    "outputId": "b400ee1b-1f89-4d4f-e63a-dd6ff146d180"
   },
   "outputs": [],
   "source": [
    "var = 'sqft'\n",
    "sns.regplot(df[var], df['price'], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yrCumELBSwC5"
   },
   "source": [
    "The relationship looks linear with some spreading as sqft increases.  \n",
    "We can also see there are some houses with almost zero square feet! Let's investigate why:  \n",
    "  \n",
    "First, a quick note on `pandas.DataFrame` indexing:  \n",
    "* `df['sqft'] < condition` gives us a \"truth array\" where True values match the condition and False otherwise. If we index the original DataFrame with this truth array we get a filtered result  \n",
    "  \n",
    "See [pandas documentiation on indexing](https://pandas.pydata.org/pandas-docs/stable/indexing.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FEOtl6DFSwC5",
    "outputId": "2a82b156-f7e3-4cc1-97c8-3c2aee5b6d49"
   },
   "outputs": [],
   "source": [
    "# filter the DataFrame with nearly zero sqft\n",
    "df[df['sqft'] < 10].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DAnGxeNdSwC7"
   },
   "source": [
    "Looks like we have some bad data from the web scraping. We will remember to remove these when we get to our data cleaning notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xXuDpEsGSwC8"
   },
   "source": [
    "### Plot `price` vs. `bed`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ugDg3f8rSwC8",
    "outputId": "10878384-4ca0-47a0-dd47-d3ffd7e31685"
   },
   "outputs": [],
   "source": [
    "var = 'bed'\n",
    "sns.regplot(df[var], df['price'], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g8EQMq0DSwC-"
   },
   "source": [
    "We observe a bit of a positive correlation between price and number of bedrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cNnNEA2zSwC_"
   },
   "source": [
    "### Plot `price` vs. `bath`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "urVjkIrnSwC_",
    "outputId": "387e3549-3f9e-4969-8359-39b3fc6a8169"
   },
   "outputs": [],
   "source": [
    "var = 'bath'\n",
    "sns.regplot(df[var], df['price'], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8-Naw0AQSwDB"
   },
   "source": [
    "Positive correlation between number of baths and price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i0CNLq2OSwDC"
   },
   "source": [
    "## Generate a correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WnCkhxG7SwDC"
   },
   "source": [
    "A correlation matrix will graphically show us which variables are most correlated to our target variable `price`.  \n",
    "A positive correlation (w.r.t. price) means as the variable increases, the price increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5hwZdHyBSwDF",
    "outputId": "ab6c4e01-0516-45fd-d7cb-4823d1b0b176"
   },
   "outputs": [],
   "source": [
    "corrmat = df.corr()\n",
    "sns.heatmap(corrmat, vmax=1, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YFXRyXDSwDH"
   },
   "source": [
    "Observe the `price` across a row or column to get an idea which variables are most likely to correlate to price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2_7S0IVvSwDH"
   },
   "source": [
    "## Categorical Variables.  \n",
    "So far we have only dealt with numeric variables however there are several non-numerical (**Categorical**) variables to be investigated as well:  \n",
    "  \n",
    "Categorical variables are ones which provide information but are not quantified numerically. For instance, the `postal_code` variable gives us information about which neighbourhood the house is located. We found from our map plot that this data may be useful for predicting `price`.  \n",
    "  \n",
    "In order to use these categorical variables in our model, we encode them into a numerical representation called a [Dummy Variable]. We cover Dummy Variables in a later notebook.\n",
    "[Dummy Variable]: https://en.wikipedia.org/wiki/Dummy_variable_(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "r1_33XtBSwDI",
    "outputId": "51ac579b-2412-4f63-eb26-8fb03f7236be"
   },
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V3UiQkl1SwDK"
   },
   "source": [
    "Let's choose `property_type`, and `postal_code` to investigate.  \n",
    "We can use the `unique()` function on the categorical columns to see the different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ixr9ugBtSwDL",
    "outputId": "5071045a-9a3c-4478-ff60-c40dee8d6c22"
   },
   "outputs": [],
   "source": [
    "print(df['postal_code'].value_counts())\n",
    "print(df['property_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tBZrxtwHSwDO"
   },
   "source": [
    "There are some variables with only a single value, let's get rid of that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "n9J1-TchSwDO",
    "outputId": "274afa4f-0df6-4e0d-e631-ef6184c2e36e"
   },
   "outputs": [],
   "source": [
    "postal_codes = [\n",
    "'94530',\n",
    "'94014',\n",
    "'94608',\n",
    "'94607',\n",
    "'94005',\n",
    "'94706',\n",
    "'94501'\n",
    "]\n",
    "for postal_code in postal_codes:\n",
    "    df = df[df.postal_code != int(postal_code)]\n",
    "property_types = ['townhouse', 'foreclosure']\n",
    "for property_type in property_types:\n",
    "    df = df[df.property_type != property_type]\n",
    "print(df['postal_code'].value_counts())\n",
    "print(df['property_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dt42s-UySwDR"
   },
   "source": [
    "Visualize these categories as box plots.  \n",
    "We use the `pandas.melt()` function to flatten our variables into a single column so we can plot.  \n",
    "The result of using `melt()` is most easily understood by displaying the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "g-RU-sZhSwDS",
    "outputId": "3b364154-5705-4962-ea7d-bc748f862da2"
   },
   "outputs": [],
   "source": [
    "vars_to_analyze = ['property_type', 'postal_code']\n",
    "df_melt = pd.melt(df, id_vars=['price'], value_vars=vars_to_analyze)\n",
    "for var in vars_to_analyze:\n",
    "    df_var = df_melt[df_melt['variable'] == var]\n",
    "    sns.boxplot(x=df_var['value'], y=df_var['price'])\n",
    "    x=plt.xticks(rotation=45)\n",
    "    plt.title(var)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "03I6hrr6SwDU"
   },
   "outputs": [],
   "source": [
    "# uncomment to see the effects of melt()\n",
    "# df_melt.head(20)\n",
    "# df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wMcJwo6kSwDW"
   },
   "source": [
    "## Analysis of variance (ANOVA)\n",
    "We use ANOVA to explore how much variance occurs **between** groups (ie. *[price vs property_type]* vs *[price vs postal_code]*) versus how much variance occurs **within** each group (ie *[price vs sub_area]* alone).  \n",
    "In the end this tells us is how useful it will be to group `price` into these 4 groups (and if including each variable in our model is useful to us).  \n",
    "Here's a quick YouTube video that may better explain ANOVA:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SyusT73oSwDW",
    "outputId": "add777f5-37ec-49eb-bade-e57ce31a2df0"
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(id='ITf4vHhyGpc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "y0s7PUdvSwDX",
    "outputId": "6c357508-3c5d-4a05-a69d-8f8da9309ef6"
   },
   "outputs": [],
   "source": [
    "def anova(df):\n",
    "    anv = pd.DataFrame()\n",
    "    anv['feature'] = vars_to_analyze\n",
    "    pvals = []\n",
    "#     import pdb; pdb.set_trace()\n",
    "    for c in vars_to_analyze:\n",
    "        samples = []\n",
    "        for cls in df[c].unique():\n",
    "            s = df[df[c] == cls]['price'].values\n",
    "            samples.append(s)\n",
    "        try:\n",
    "            pval = stats.f_oneway(*samples)[1]\n",
    "        except Exception as e:\n",
    "            pval=None\n",
    "            print(e)\n",
    "        finally:\n",
    "            pvals.append(pval)\n",
    "    anv['pval'] = pvals\n",
    "    return anv.sort_values('pval')\n",
    "\n",
    "a = anova(df.dropna())\n",
    "a['disparity'] = np.log(1./a['pval'].values)\n",
    "sns.barplot(data=a, x='feature', y='disparity')\n",
    "x=plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eLZKI9uhSwDZ"
   },
   "source": [
    "This gives us a rough estimate of effect each variable will have on our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LpXiYui9SwDa"
   },
   "source": [
    "# Save our DataFrame to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BFcqNFxXSwDa"
   },
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(data_dir,'data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h_Xu0BacSwDd"
   },
   "source": [
    "## Hopefully the EDA has improved our intuition about the dataset. Now we can move onto data cleaning!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "1 - Exploratory Data Analysis.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
